# ðŸ¥œ chota-tinker
Some infra to speed up tinkering with RL on smaller-scale


> [!TIP]
> "chota" stands for mini in Hindi ðŸ˜„


## TODOs
- [ ] see if training works or not
- [ ] we need to speed up training
    - [ ] fused loss fns
    - [ ] we can have custom model impl. for better memory and throughput during training, like: (https://github.com/NovaSky-AI/SkyRL/blob/main/skyrl-tx/tx/models/qwen3.py)[SkyRL tx]
    - [ ] add other baselines
        - [ ] MARA